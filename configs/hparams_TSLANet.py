## The cuurent hyper-parameters values are not necessarily the best ones for a specific risk.
def get_hparams_class(dataset_name):
    """Return the algorithm class with the given name."""
    if dataset_name not in globals():
        raise NotImplementedError("Dataset not found: {}".format(dataset_name))
    return globals()[dataset_name]


class EEG():
    def __init__(self):
        super(EEG, self).__init__()
        self.train_params = {
            'num_epochs': 20,  # 20, #4,
            'num_epochs_pr': 20,  # 20,
            'weight_decay': 1e-4,

        }
        self.alg_hparams = {'DANCE': {'batch_size': 64,
           'eta': 1.7000000000000002,
           'learning_rate': 0.0001,
           'margin': 0.8500000000000001,
           'num_epochs': 20,
           'num_epochs_pr': 20,
           'weight_decay': 0.0001},
 'OVANet': {'batch_size': 64,
            'learning_rate': 0.01,
            'num_epochs': 20,
            'num_epochs_pr': 20,
            'weight_decay': 0.0001},
 'PPOT': {'alpha': 0.01,
          'batch_size': 64,
          'beta': 0.001,
          'learning_rate': 0.0001,
          'n_entropy': 1.7000000000000002,
          'neg': 0.5,
          'num_epochs': 20,
          'num_epochs_pr': 20,
          'ot': 0.7500000000000001,
          'p_entropy': 0.1,
          'reg': 0.1,
          'tau': 0.5,
          'tau1': 0.8500000000000001,
          'tau2': 1.2000000000000002,
          'thresh': 0.7500000000000001,
          'weight_decay': 0.0001},
 'UDA': {'batch_size': 32,
         'domain_loss_wt': 4.8500000000000005,
         'learning_rate': 0.0005,
         'num_epochs': 20,
         'num_epochs_pr': 20,
         'src_cls_loss_wt': 4.95,
         'w0': 0.55,
         'weight_decay': 0.0001},
 'UniJDOT': {'K': 20,
             'alpha': 0.15000000000000002,
             'batch_size': 32,
             'joint_decision': True,
             'lamb': 0.7000000000000001,
             'learning_rate': 0.001,
             'n_batch': 30,
             'num_epochs': 20,
             'num_epochs_pr': 20,
             'src_weight': 1.35,
             'threshold_method': 'threshold_yen',
             'trg_mem_size': 32,
             'weight_decay': 0.0001},
 'UniOT': {'K': 15,
           'MQ_size': 2000,
           'batch_size': 32,
           'gamma': 0.95,
           'lam': 0.15000000000000002,
           'learning_rate': 0.0001,
           'mu': 0.2,
           'num_epochs': 20,
           'num_epochs_pr': 20,
           'temp': 0.05,
           'weight_decay': 0.0001}}


class HHAR():
    def __init__(self):
        super().__init__()
        self.train_params = {
            'num_epochs': 20,  # 4, #50,#160, #50,#160, #250,
            'num_epochs_pr': 20,
            'weight_decay': 1e-4,
        }
        self.alg_hparams = {'DANCE': {'batch_size': 32,
           'eta': 3.2,
           'learning_rate': 0.0001,
           'margin': 0.9000000000000001,
           'num_epochs': 20,
           'num_epochs_pr': 20,
           'weight_decay': 0.0001},
 'OVANet': {'batch_size': 64,
            'learning_rate': 0.0001,
            'num_epochs': 20,
            'num_epochs_pr': 20,
            'weight_decay': 0.0001},
 'PPOT': {'alpha': 0.001,
          'batch_size': 32,
          'beta': 0.001,
          'learning_rate': 0.001,
          'n_entropy': 0.2,
          'neg': 0.5,
          'num_epochs': 20,
          'num_epochs_pr': 20,
          'ot': 0.5,
          'p_entropy': 0.5,
          'reg': 0.1,
          'tau': 0.25,
          'tau1': 0.6000000000000001,
          'tau2': 1.35,
          'thresh': 1,
          'weight_decay': 0.0001},
 'UDA': {'batch_size': 32,
         'domain_loss_wt': 4.25,
         'learning_rate': 0.001,
         'num_epochs': 20,
         'num_epochs_pr': 20,
         'src_cls_loss_wt': 4.25,
         'w0': 0.05,
         'weight_decay': 0.0001},
 'UniJDOT': {'K': 20,
             'alpha': 0.8500000000000001,
             'batch_size': 64,
             'joint_decision': True,
             'lamb': 1.55,
             'learning_rate': 0.0001,
             'n_batch': 15,
             'num_epochs': 20,
             'num_epochs_pr': 20,
             'src_weight': 1.4,
             'threshold_method': 'threshold_yen',
             'trg_mem_size': 128,
             'weight_decay': 0.0001},
 'UniOT': {'K': 20,
           'MQ_size': 1000,
           'batch_size': 64,
           'gamma': 0.7500000000000001,
           'lam': 0.6000000000000001,
           'learning_rate': 0.0001,
           'mu': 0.8500000000000001,
           'num_epochs': 20,
           'num_epochs_pr': 20,
           'temp': 0.05,
           'weight_decay': 0.0001}}


class HAR():
    def __init__(self):
        super(HAR, self).__init__()
        self.train_params = {
            'num_epochs': 20,  # 4, #50,#160, #50,#160, #250,
            'num_epochs_pr': 20,
            # 64*2*2,
            'weight_decay': 1e-4,
        }
        self.alg_hparams = {'DANCE': {'batch_size': 64,
           'eta': 0.55,
           'learning_rate': 0.0001,
           'margin': 1,
           'num_epochs': 20,
           'num_epochs_pr': 20,
           'weight_decay': 0.0001},
 'OVANet': {'batch_size': 64,
            'learning_rate': 0.005,
            'num_epochs': 20,
            'num_epochs_pr': 20,
            'weight_decay': 0.0001},
 'PPOT': {'alpha': 0.01,
          'batch_size': 64,
          'beta': 0.001,
          'learning_rate': 0.0001,
          'n_entropy': 0.7500000000000001,
          'neg': 0.4,
          'num_epochs': 20,
          'num_epochs_pr': 20,
          'ot': 2.9,
          'p_entropy': 0.3,
          'reg': 0.1,
          'tau': 0.2,
          'tau1': 0.5,
          'tau2': 1.6,
          'thresh': 1,
          'weight_decay': 0.0001},
 'UDA': {'batch_size': 64,
         'domain_loss_wt': 2.3,
         'learning_rate': 0.001,
         'num_epochs': 20,
         'num_epochs_pr': 20,
         'src_cls_loss_wt': 4.5,
         'w0': 0.4,
         'weight_decay': 0.0001},
 'UniJDOT': {'K': 5,
             'alpha': 1.8,
             'batch_size': 64,
             'joint_decision': True,
             'lamb': 3.25,
             'learning_rate': 0.0005,
             'n_batch': 15,
             'num_epochs': 20,
             'num_epochs_pr': 20,
             'src_weight': 3.65,
             'threshold_method': 'threshold_yen',
             'trg_mem_size': 128,
             'weight_decay': 0.0001},
 'UniOT': {'K': 15,
           'MQ_size': 2000,
           'batch_size': 32,
           'gamma': 1,
           'lam': 0.1,
           'learning_rate': 0.0001,
           'mu': 0.95,
           'num_epochs': 20,
           'num_epochs_pr': 20,
           'temp': 0.05,
           'weight_decay': 0.0001}}
